# 🤖 AI Face & Hand Gesture Recognition with Voice Assistant

Pet-проєкт з комп’ютерного зору та інтерактивної логіки, який у **реальному часі**:

- 👤 розпізнає обличчя людей
- ✋ відстежує руки та відображає **скелет руки**
- 👋 розпізнає жести (статичні та динамічні)
- 🗣️ реагує **голосовим асистентом**
- 🧠 поєднує всі сигнали в єдину систему поведінки

Проєкт створений як **інженерний pet-проєкт** для навчання, портфоліо та демонстрації реального CV-пайплайну.

---

## 🎯 Цілі проєкту

- Побудувати повноцінну real-time систему комп’ютерного зору
- Попрацювати з live-відео з вебкамери
- Навчитись:
  - face embeddings і similarity search
  - hand landmarks і skeleton
  - gesture recognition
  - подієво-орієнтованої логіки
- Інтегрувати **голосовий асистент** у CV-систему

---

## 🧠 Основна ідея

Система побудована за модульним принципом:

- 👤 **Обличчя**
  - embeddings замість класичної класифікації
  - порівняння через threshold
- ✋ **Руки**
  - MediaPipe Hands
  - landmarks + skeleton
  - логіка жестів без нейромереж
- 🧩 **Логіка**
  - rule-based controller
  - cooldown, контекст користувача
- 🗣️ **Голос**
  - асинхронна озвучка подій
  - не блокує відеопотік

---

## 🧱 Архітектура

```
Webcam
  ↓
Frame Capture (OpenCV)
  ↓
┌────────────────────────────┐
│ Face Recognition Module    │ → user_id | unknown
├────────────────────────────┤
│ Hand Gesture Module        │ → gesture type
└────────────────────────────┘
  ↓
Controller / Logic Layer
  ↓
Voice Assistant / UI / Actions
```

---

## 🗂️ Структура проєкту

```
project/
│
├── main.py                 # Точка входу
│
├── camera/
│   └── capture.py          # Отримання кадрів з камери
│
├── face/
│   ├── detector.py         # Детекція облич
│   ├── embedder.py         # Face embeddings
│   └── recognizer.py       # Порівняння облич
│
├── gestures/
│   ├── collect/            # Збір датасету
│   ├── model/              # Тренування моделей
│   └── predictor.py        # Розпізнавання жестів
│
├── core/
│   └── controller.py       # Логіка прийняття рішень
│
├── data/
│   ├── faces/              # Embeddings користувачів
│   └── gestures/           # Landmarks жестів
│
├── models/
│   ├── face/
│   └── gesture/
│
└── requirements.txt
```

---

## 🛠️ Технології

- **Python 3.10+**
- **OpenCV** — відеопотік і відображення
- **MediaPipe Hands** — landmarks та skeleton руки
- **InsightFace** — face embeddings
- **NumPy** — обчислення
- **Pillow (PIL)** — український текст на відео
- **edge_tts + pygame** — голосовий асистент

---

## ✋ Жести (MVP)

| Жест         | Тип     |
| ------------ | ------- |
| 👍 thumbs_up | static  |
| 👋 wave      | dynamic |

---

## 👤 Обличчя

- Для кожного користувача зберігається **embedding**
- Підтримується **декілька фото на одну людину**
- Розпізнавання через similarity
- Якщо distance < threshold → користувач відомий
- Імʼя відображається **українською мовою над обличчям**

---

## 🗣️ Голосовий асистент

Система містить **вбудований голосовий асистент**, який реагує на події:

### 🔊 Що озвучується
- поява знайомого користувача
- виконання жесту
- запуск дій (наприклад, відкриття сайту)

---

### ⚙️ Технічні деталі
- використовується **gTTS (Google Text-to-Speech)**
- мова: **українська**
- озвучка запускається **в окремому потоці**
- відеопотік не блокується
- є cooldown, щоб уникнути спаму

## ▶️ Запуск

```bash
pip install -r requirements.txt
python main.py
```
Після запуску:
- відкривається камера
- видно bounding box обличчя з імʼям
- відображається скелет руки
- жести обробляються в реальному часі
- система реагує голосом

---

## 🚀 Roadmap

- [ ] Face detection + recognition
- [ ] Static gesture recognition
- [ ] Dynamic gestures (LSTM)
- [ ] Controller (rules + cooldown)
- [ ] UI / sound feedback

---

## 📌 Примітка

Це **pet-проєкт**, орієнтований на **якість архітектури**, а не кількість магії.
